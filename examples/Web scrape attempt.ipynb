{"cells":[{"cell_type":"code","source":"import pandas as _hex_pandas\nimport datetime as _hex_datetime\nimport json as _hex_json","execution_count":null,"metadata":{},"outputs":[]},{"cell_type":"code","source":"hex_scheduled = _hex_json.loads(\"false\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_user_email = _hex_json.loads(\"\\\"example-user@example.com\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_user_attributes = _hex_json.loads(\"{}\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_run_context = _hex_json.loads(\"\\\"logic\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_timezone = _hex_json.loads(\"\\\"America/New_York\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_project_id = _hex_json.loads(\"\\\"0198e707-161f-7003-bc17-9a8d006d2b71\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_project_name = _hex_json.loads(\"\\\"Web scrape attempt\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_status = _hex_json.loads(\"\\\"\\\"\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_categories = _hex_json.loads(\"[]\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"hex_color_palette = _hex_json.loads(\"[\\\"#4C78A8\\\",\\\"#F58518\\\",\\\"#E45756\\\",\\\"#72B7B2\\\",\\\"#54A24B\\\",\\\"#EECA3B\\\",\\\"#B279A2\\\",\\\"#FF9DA6\\\",\\\"#9D755D\\\",\\\"#BAB0AC\\\"]\")","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":"!uv pip install playwright\n!playwright install","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"\u001b[2mUsing Python 3.11.11 environment at: /home/hexuser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.11\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m4 packages\u001b[0m \u001b[2min 105ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)                                                   \n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m     0 B/43.79 MiB                     \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 14.90 KiB/43.79 MiB                   \u001b[1A\n\u001b[2mpyee      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/15.36 KiB\n\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 14.90 KiB/43.79 MiB                   \u001b[2A\n\u001b[2mpyee      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 14.91 KiB/15.36 KiB\n\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 14.90 KiB/43.79 MiB                   \u001b[2A\n\u001b[2mpyee      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 14.91 KiB/15.36 KiB\n\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 30.90 KiB/43.79 MiB                   \u001b[2A\n\u001b[2mpyee      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 14.91 KiB/15.36 KiB\n\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 46.90 KiB/43.79 MiB                   \u001b[2A\n\u001b[2mpyee      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 14.91 KiB/15.36 KiB\n\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 62.90 KiB/43.79 MiB                   \u001b[2A\n\u001b[2mpyee      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 14.91 KiB/15.36 KiB\n\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 76.81 KiB/43.79 MiB                   \u001b[2A\n\u001b[2mpyee      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 14.91 KiB/15.36 KiB\n\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 92.81 KiB/43.79 MiB                   \u001b[2A\n\u001b[2mpyee      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 15.36 KiB/15.36 KiB\n\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 92.81 KiB/43.79 MiB                   \u001b[2A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 92.81 KiB/43.79 MiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 108.81 KiB/43.79 MiB                  \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 124.81 KiB/43.79 MiB                  \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 140.81 KiB/43.79 MiB                  \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 156.81 KiB/43.79 MiB                  \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 172.81 KiB/43.79 MiB                  \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 188.81 KiB/43.79 MiB                  \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 204.81 KiB/43.79 MiB                  \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 556.81 KiB/43.79 MiB                  \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/2)----\u001b[0m\u001b[0m 4.51 MiB/43.79 MiB                    \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[0m\u001b[0m 8.96 MiB/43.79 MiB                    \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[0m\u001b[0m 13.53 MiB/43.79 MiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[0m\u001b[0m 18.17 MiB/43.79 MiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[0m\u001b[0m 22.50 MiB/43.79 MiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[0m\u001b[0m 27.20 MiB/43.79 MiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[0m\u001b[0m 32.36 MiB/43.79 MiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)----\u001b[0m\u001b[0m 36.95 MiB/43.79 MiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)[2m-\u001b[0m\u001b[0m 41.26 MiB/43.79 MiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/2)[2m-\u001b[0m\u001b[0m 42.12 MiB/43.79 MiB                   \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 606ms\u001b[0m\u001b[0m                                                 \u001b[1A\n\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 23ms\u001b[0m\u001b[0m                                \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mplaywright\u001b[0m\u001b[2m==1.54.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyee\u001b[0m\u001b[2m==13.0.0\u001b[0m\nDownloading Chromium 139.0.7258.5 (playwright build v1181)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1181/chromium-linux.zip\u001b[22m\n\u001b[1G172.5 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G172.5 MiB [                    ] 0% 25.9s\u001b[0K\u001b[1G172.5 MiB [                    ] 0% 17.8s\u001b[0K\u001b[1G172.5 MiB [                    ] 0% 6.8s\u001b[0K\u001b[1G172.5 MiB [                    ] 1% 4.7s\u001b[0K\u001b[1G172.5 MiB [                    ] 1% 4.0s\u001b[0K\u001b[1G172.5 MiB [=                   ] 2% 3.2s\u001b[0K\u001b[1G172.5 MiB [=                   ] 3% 3.0s\u001b[0K\u001b[1G172.5 MiB [=                   ] 4% 2.9s\u001b[0K\u001b[1G172.5 MiB [=                   ] 5% 2.7s\u001b[0K\u001b[1G172.5 MiB [=                   ] 6% 2.4s\u001b[0K\u001b[1G172.5 MiB [=                   ] 7% 2.2s\u001b[0K\u001b[1G172.5 MiB [==                  ] 8% 2.1s\u001b[0K\u001b[1G172.5 MiB [==                  ] 9% 2.1s\u001b[0K\u001b[1G172.5 MiB [==                  ] 10% 2.0s\u001b[0K\u001b[1G172.5 MiB [==                  ] 12% 1.8s\u001b[0K\u001b[1G172.5 MiB [===                 ] 13% 1.7s\u001b[0K\u001b[1G172.5 MiB [===                 ] 14% 1.7s\u001b[0K\u001b[1G172.5 MiB [===                 ] 15% 1.6s\u001b[0K\u001b[1G172.5 MiB [===                 ] 17% 1.6s\u001b[0K\u001b[1G172.5 MiB [====                ] 18% 1.5s\u001b[0K\u001b[1G172.5 MiB [====                ] 19% 1.5s\u001b[0K\u001b[1G172.5 MiB [====                ] 20% 1.4s\u001b[0K\u001b[1G172.5 MiB [=====               ] 22% 1.3s\u001b[0K\u001b[1G172.5 MiB [=====               ] 23% 1.3s\u001b[0K\u001b[1G172.5 MiB [=====               ] 24% 1.3s\u001b[0K\u001b[1G172.5 MiB [=====               ] 25% 1.3s\u001b[0K\u001b[1G172.5 MiB [=====               ] 26% 1.2s\u001b[0K\u001b[1G172.5 MiB [======              ] 29% 1.1s\u001b[0K\u001b[1G172.5 MiB [======              ] 31% 1.0s\u001b[0K\u001b[1G172.5 MiB [=======             ] 33% 1.0s\u001b[0K\u001b[1G172.5 MiB [=======             ] 35% 1.0s\u001b[0K\u001b[1G172.5 MiB [=======             ] 37% 0.9s\u001b[0K\u001b[1G172.5 MiB [========            ] 39% 0.9s\u001b[0K\u001b[1G172.5 MiB [========            ] 41% 0.8s\u001b[0K\u001b[1G172.5 MiB [=========           ] 43% 0.7s\u001b[0K\u001b[1G172.5 MiB [=========           ] 45% 0.7s\u001b[0K\u001b[1G172.5 MiB [==========          ] 47% 0.7s\u001b[0K\u001b[1G172.5 MiB [==========          ] 49% 0.6s\u001b[0K\u001b[1G172.5 MiB [==========          ] 51% 0.6s\u001b[0K\u001b[1G172.5 MiB [===========         ] 53% 0.6s\u001b[0K\u001b[1G172.5 MiB [===========         ] 55% 0.5s\u001b[0K\u001b[1G172.5 MiB [============        ] 57% 0.5s\u001b[0K\u001b[1G172.5 MiB [============        ] 59% 0.5s\u001b[0K\u001b[1G172.5 MiB [============        ] 61% 0.5s\u001b[0K\u001b[1G172.5 MiB [=============       ] 62% 0.4s\u001b[0K\u001b[1G172.5 MiB [=============       ] 64% 0.4s\u001b[0K\u001b[1G172.5 MiB [=============       ] 67% 0.4s\u001b[0K\u001b[1G172.5 MiB [==============      ] 69% 0.4s\u001b[0K\u001b[1G172.5 MiB [==============      ] 71% 0.3s\u001b[0K\u001b[1G172.5 MiB [===============     ] 73% 0.3s\u001b[0K\u001b[1G172.5 MiB [===============     ] 75% 0.3s\u001b[0K\u001b[1G172.5 MiB [===============     ] 77% 0.2s\u001b[0K\u001b[1G172.5 MiB [================    ] 79% 0.2s\u001b[0K\u001b[1G172.5 MiB [================    ] 82% 0.2s\u001b[0K\u001b[1G172.5 MiB [=================   ] 84% 0.2s\u001b[0K\u001b[1G172.5 MiB [=================   ] 85% 0.2s\u001b[0K\u001b[1G172.5 MiB [==================  ] 87% 0.1s\u001b[0K\u001b[1G172.5 MiB [==================  ] 89% 0.1s\u001b[0K\u001b[1G172.5 MiB [==================  ] 91% 0.1s\u001b[0K\u001b[1G172.5 MiB [=================== ] 93% 0.1s\u001b[0K\u001b[1G172.5 MiB [=================== ] 95% 0.0s\u001b[0K\u001b[1G172.5 MiB [=================== ] 97% 0.0s\u001b[0K\u001b[1G172.5 MiB [====================] 98% 0.0s\u001b[0K\u001b[1G172.5 MiB [====================] 100% 0.0s\u001b[0K\nChromium 139.0.7258.5 (playwright build v1181) downloaded to /home/hexuser/.cache/ms-playwright/chromium-1181\nDownloading Chromium Headless Shell 139.0.7258.5 (playwright build v1181)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1181/chromium-headless-shell-linux.zip\u001b[22m\n\u001b[1G104.8 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G104.8 MiB [                    ] 0% 17.7s\u001b[0K\u001b[1G104.8 MiB [                    ] 0% 16.5s\u001b[0K\u001b[1G104.8 MiB [                    ] 0% 12.0s\u001b[0K\u001b[1G104.8 MiB [                    ] 1% 5.6s\u001b[0K\u001b[1G104.8 MiB [                    ] 2% 3.4s\u001b[0K\u001b[1G104.8 MiB [=                   ] 3% 2.7s\u001b[0K\u001b[1G104.8 MiB [=                   ] 5% 2.1s\u001b[0K\u001b[1G104.8 MiB [=                   ] 6% 1.8s\u001b[0K\u001b[1G104.8 MiB [==                  ] 8% 1.6s\u001b[0K\u001b[1G104.8 MiB [==                  ] 9% 1.6s\u001b[0K\u001b[1G104.8 MiB [==                  ] 11% 1.4s\u001b[0K\u001b[1G104.8 MiB [===                 ] 13% 1.3s\u001b[0K\u001b[1G104.8 MiB [===                 ] 15% 1.2s\u001b[0K\u001b[1G104.8 MiB [====                ] 18% 1.0s\u001b[0K\u001b[1G104.8 MiB [====                ] 21% 0.9s\u001b[0K\u001b[1G104.8 MiB [=====               ] 23% 0.8s\u001b[0K\u001b[1G104.8 MiB [=====               ] 26% 0.8s\u001b[0K\u001b[1G104.8 MiB [======              ] 29% 0.7s\u001b[0K\u001b[1G104.8 MiB [======              ] 32% 0.6s\u001b[0K\u001b[1G104.8 MiB [=======             ] 35% 0.6s\u001b[0K\u001b[1G104.8 MiB [========            ] 38% 0.5s\u001b[0K\u001b[1G104.8 MiB [========            ] 42% 0.5s\u001b[0K\u001b[1G104.8 MiB [=========           ] 44% 0.5s\u001b[0K\u001b[1G104.8 MiB [=========           ] 47% 0.4s\u001b[0K\u001b[1G104.8 MiB [==========          ] 50% 0.4s\u001b[0K\u001b[1G104.8 MiB [===========         ] 53% 0.4s\u001b[0K\u001b[1G104.8 MiB [============        ] 57% 0.3s\u001b[0K\u001b[1G104.8 MiB [============        ] 61% 0.3s\u001b[0K\u001b[1G104.8 MiB [=============       ] 64% 0.3s\u001b[0K\u001b[1G104.8 MiB [==============      ] 67% 0.2s\u001b[0K\u001b[1G104.8 MiB [==============      ] 71% 0.2s\u001b[0K\u001b[1G104.8 MiB [===============     ] 74% 0.2s\u001b[0K\u001b[1G104.8 MiB [================    ] 78% 0.1s\u001b[0K\u001b[1G104.8 MiB [=================   ] 82% 0.1s\u001b[0K\u001b[1G104.8 MiB [=================   ] 85% 0.1s\u001b[0K\u001b[1G104.8 MiB [==================  ] 89% 0.1s\u001b[0K\u001b[1G104.8 MiB [==================  ] 91% 0.1s\u001b[0K\u001b[1G104.8 MiB [=================== ] 95% 0.0s\u001b[0K\u001b[1G104.8 MiB [====================] 98% 0.0s\u001b[0K\u001b[1G104.8 MiB [====================] 100% 0.0s\u001b[0K\nChromium Headless Shell 139.0.7258.5 (playwright build v1181) downloaded to /home/hexuser/.cache/ms-playwright/chromium_headless_shell-1181\nDownloading Firefox 140.0.2 (playwright build v1489)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/firefox/1489/firefox-debian-12.zip\u001b[22m\n\u001b[1G92.5 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G92.5 MiB [                    ] 0% 13.7s\u001b[0K\u001b[1G92.5 MiB [                    ] 0% 6.3s\u001b[0K\u001b[1G92.5 MiB [                    ] 1% 2.6s\u001b[0K\u001b[1G92.5 MiB [=                   ] 3% 1.7s\u001b[0K\u001b[1G92.5 MiB [=                   ] 5% 1.3s\u001b[0K\u001b[1G92.5 MiB [==                  ] 7% 1.1s\u001b[0K\u001b[1G92.5 MiB [==                  ] 9% 1.0s\u001b[0K\u001b[1G92.5 MiB [==                  ] 10% 1.0s\u001b[0K\u001b[1G92.5 MiB [===                 ] 12% 1.0s\u001b[0K\u001b[1G92.5 MiB [===                 ] 13% 1.0s\u001b[0K\u001b[1G92.5 MiB [===                 ] 15% 1.0s\u001b[0K\u001b[1G92.5 MiB [====                ] 17% 0.9s\u001b[0K\u001b[1G92.5 MiB [====                ] 20% 0.8s\u001b[0K\u001b[1G92.5 MiB [=====               ] 24% 0.7s\u001b[0K\u001b[1G92.5 MiB [=====               ] 27% 0.6s\u001b[0K\u001b[1G92.5 MiB [======              ] 29% 0.6s\u001b[0K\u001b[1G92.5 MiB [=======             ] 32% 0.6s\u001b[0K\u001b[1G92.5 MiB [=======             ] 35% 0.5s\u001b[0K\u001b[1G92.5 MiB [========            ] 38% 0.5s\u001b[0K\u001b[1G92.5 MiB [========            ] 42% 0.4s\u001b[0K\u001b[1G92.5 MiB [=========           ] 45% 0.4s\u001b[0K\u001b[1G92.5 MiB [==========          ] 48% 0.4s\u001b[0K\u001b[1G92.5 MiB [==========          ] 51% 0.3s\u001b[0K\u001b[1G92.5 MiB [===========         ] 54% 0.3s\u001b[0K\u001b[1G92.5 MiB [===========         ] 57% 0.3s\u001b[0K\u001b[1G92.5 MiB [============        ] 60% 0.3s\u001b[0K\u001b[1G92.5 MiB [=============       ] 64% 0.2s\u001b[0K\u001b[1G92.5 MiB [=============       ] 67% 0.2s\u001b[0K\u001b[1G92.5 MiB [==============      ] 70% 0.2s\u001b[0K\u001b[1G92.5 MiB [===============     ] 74% 0.2s\u001b[0K\u001b[1G92.5 MiB [===============     ] 76% 0.2s\u001b[0K\u001b[1G92.5 MiB [================    ] 78% 0.1s\u001b[0K\u001b[1G92.5 MiB [================    ] 80% 0.1s\u001b[0K\u001b[1G92.5 MiB [=================   ] 83% 0.1s\u001b[0K\u001b[1G92.5 MiB [=================   ] 86% 0.1s\u001b[0K\u001b[1G92.5 MiB [==================  ] 89% 0.1s\u001b[0K\u001b[1G92.5 MiB [=================== ] 93% 0.0s\u001b[0K\u001b[1G92.5 MiB [=================== ] 96% 0.0s\u001b[0K\u001b[1G92.5 MiB [====================] 100% 0.0s\u001b[0K\nFirefox 140.0.2 (playwright build v1489) downloaded to /home/hexuser/.cache/ms-playwright/firefox-1489\nDownloading Webkit 26.0 (playwright build v2191)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/webkit/2191/webkit-debian-12.zip\u001b[22m\n\u001b[1G94.2 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G94.2 MiB [                    ] 0% 14.8s\u001b[0K\u001b[1G94.2 MiB [                    ] 0% 9.8s\u001b[0K\u001b[1G94.2 MiB [                    ] 1% 4.7s\u001b[0K\u001b[1G94.2 MiB [                    ] 1% 3.5s\u001b[0K\u001b[1G94.2 MiB [=                   ] 3% 2.6s\u001b[0K\u001b[1G94.2 MiB [=                   ] 5% 1.8s\u001b[0K\u001b[1G94.2 MiB [=                   ] 7% 1.4s\u001b[0K\u001b[1G94.2 MiB [==                  ] 9% 1.3s\u001b[0K\u001b[1G94.2 MiB [==                  ] 10% 1.3s\u001b[0K\u001b[1G94.2 MiB [==                  ] 11% 1.2s\u001b[0K\u001b[1G94.2 MiB [===                 ] 13% 1.2s\u001b[0K\u001b[1G94.2 MiB [===                 ] 14% 1.1s\u001b[0K\u001b[1G94.2 MiB [===                 ] 16% 1.1s\u001b[0K\u001b[1G94.2 MiB [====                ] 18% 1.0s\u001b[0K\u001b[1G94.2 MiB [====                ] 20% 0.9s\u001b[0K\u001b[1G94.2 MiB [=====               ] 23% 0.9s\u001b[0K\u001b[1G94.2 MiB [=====               ] 25% 0.8s\u001b[0K\u001b[1G94.2 MiB [======              ] 27% 0.8s\u001b[0K\u001b[1G94.2 MiB [======              ] 30% 0.7s\u001b[0K\u001b[1G94.2 MiB [=======             ] 32% 0.7s\u001b[0K\u001b[1G94.2 MiB [=======             ] 35% 0.6s\u001b[0K\u001b[1G94.2 MiB [========            ] 38% 0.6s\u001b[0K\u001b[1G94.2 MiB [========            ] 40% 0.5s\u001b[0K\u001b[1G94.2 MiB [=========           ] 43% 0.5s\u001b[0K\u001b[1G94.2 MiB [=========           ] 46% 0.5s\u001b[0K\u001b[1G94.2 MiB [==========          ] 48% 0.4s\u001b[0K\u001b[1G94.2 MiB [==========          ] 51% 0.4s\u001b[0K\u001b[1G94.2 MiB [===========         ] 54% 0.4s\u001b[0K\u001b[1G94.2 MiB [===========         ] 57% 0.3s\u001b[0K\u001b[1G94.2 MiB [============        ] 60% 0.3s\u001b[0K\u001b[1G94.2 MiB [=============       ] 63% 0.3s\u001b[0K\u001b[1G94.2 MiB [==============      ] 68% 0.2s\u001b[0K\u001b[1G94.2 MiB [==============      ] 72% 0.2s\u001b[0K\u001b[1G94.2 MiB [===============     ] 75% 0.2s\u001b[0K\u001b[1G94.2 MiB [================    ] 79% 0.1s\u001b[0K\u001b[1G94.2 MiB [================    ] 82% 0.1s\u001b[0K\u001b[1G94.2 MiB [=================   ] 86% 0.1s\u001b[0K\u001b[1G94.2 MiB [==================  ] 89% 0.1s\u001b[0K\u001b[1G94.2 MiB [=================== ] 93% 0.0s\u001b[0K\u001b[1G94.2 MiB [=================== ] 96% 0.0s\u001b[0K\u001b[1G94.2 MiB [====================] 100% 0.0s\u001b[0K\nWebkit 26.0 (playwright build v2191) downloaded to /home/hexuser/.cache/ms-playwright/webkit-2191\nDownloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n\u001b[1G2.3 MiB [                    ] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [=                   ] 4% 0.3s\u001b[0K\u001b[1G2.3 MiB [===                 ] 15% 0.2s\u001b[0K\u001b[1G2.3 MiB [===========         ] 56% 0.0s\u001b[0K\u001b[1G2.3 MiB [====================] 100% 0.0s\u001b[0K\nFFMPEG playwright build v1011 downloaded to /home/hexuser/.cache/ms-playwright/ffmpeg-1011\nPlaywright Host validation warning: \n╔══════════════════════════════════════════════════════╗\n║ Host system is missing dependencies to run browsers. ║\n║ Missing libraries:                                   ║\n║     libgtk-4.so.1                                    ║\n║     libgraphene-1.0.so.0                             ║\n║     libwoff2dec.so.1.0.2                             ║\n║     libgstallocators-1.0.so.0                        ║\n║     libgstapp-1.0.so.0                               ║\n║     libgstpbutils-1.0.so.0                           ║\n║     libgstaudio-1.0.so.0                             ║\n║     libgsttag-1.0.so.0                               ║\n║     libgstvideo-1.0.so.0                             ║\n║     libgstgl-1.0.so.0                                ║\n║     libgstcodecparsers-1.0.so.0                      ║\n║     libgstfft-1.0.so.0                               ║\n║     libenchant-2.so.2                                ║\n║     libsecret-1.so.0                                 ║\n║     libhyphen.so.0                                   ║\n║     libmanette-0.2.so.0                              ║\n╚══════════════════════════════════════════════════════╝\n    at validateDependenciesLinux (/home\u001b[90m/hexu\u001b[39mser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.11/lib/python3.11/site-packages/playwright/driver/package/lib/server/registry/dependencies.js:269:9)\n\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\u001b[39m\n    at async Registry._validateHostRequirements (/home\u001b[90m/hexu\u001b[39mser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.11/lib/python3.11/site-packages/playwright/driver/package/lib/server/registry/index.js:914:14)\n    at async Registry._validateHostRequirementsForExecutableIfNeeded (/home\u001b[90m/hexu\u001b[39mser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.11/lib/python3.11/site-packages/playwright/driver/package/lib/server/registry/index.js:1036:7)\n    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/home\u001b[90m/hexu\u001b[39mser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.11/lib/python3.11/site-packages/playwright/driver/package/lib/server/registry/index.js:1025:7)\n    at async i.<anonymous> (/home\u001b[90m/hexu\u001b[39mser/.cache/pypoetry/virtualenvs/python-kernel-OtKFaj5M-py3.11/lib/python3.11/site-packages/playwright/driver/package/lib/cli/program.js:222:7)\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"import asyncio, re, random\nfrom pathlib import Path\nimport pandas as pd\nfrom urllib.parse import urljoin\nfrom playwright.async_api import async_playwright, TimeoutError as PWTimeout\n\nBASE = \"https://www.trulieve.com\"\nDISPENSARIES_URL = f\"{BASE}/dispensaries\"\nCATEGORY_URL = f\"{BASE}/category/flower/whole-flower\"\nSUBCATEGORY   = \"Whole Flower\"\nOUT_PREFIX    = \"trulieve_FL_whole_flower\"\n\nPRICE_RE        = re.compile(r\"\\$\\s*([0-9]+(?:\\.[0-9]{2})?)\")\nSIZE_RE         = re.compile(r\"\\b(0\\.5g|1g|2g|3\\.5g|7g|10g|14g|28g)\\b\", re.I)\nTHC_SINGLE_RE   = re.compile(r\"\\bTHC\\b[^0-9]*([0-9]+(?:\\.[0-9]+)?)\\s*%\", re.I)\nTHC_RANGE_RE    = re.compile(r\"\\bTHC\\b[^0-9]*([0-9]+(?:\\.[0-9]+)?)\\s*%[^0-9]+([0-9]+(?:\\.[0-9]+)?)\\s*%\", re.I)\nSIZE_MAP = {\"0.5g\":0.5,\"1g\":1.0,\"2g\":2.0,\"3.5g\":3.5,\"7g\":7.0,\"10g\":10.0,\"14g\":14.0,\"28g\":28.0}\ndef grams_from_size(s): return SIZE_MAP.get((s or \"\").lower())\n\ndef looks_like_florida(href, text):\n    t=(text or \"\").upper(); h=(href or \"\").lower()\n    return (\", FL\" in t) or t.endswith(\" FL\") or \" FL \" in t or any(v in h for v in (\"/florida\",\"-fl-\")) or h.endswith((\"/fl\",\"-fl\"))\n\ndef product_slug(href):\n    try: return href.split(\"/product/\",1)[1].split(\"?\",1)[0].split(\"#\",1)[0].strip(\"/\")\n    except: return href or \"\"\n\nasync def extract_fl_store_links(page):\n    await page.goto(DISPENSARIES_URL, wait_until=\"networkidle\")\n    anchors = await page.locator(\"a[href^='/dispensaries/']\").all()\n    out, seen = [], set()\n    for a in anchors:\n        href = await a.get_attribute(\"href\"); txt = (await a.text_content() or \"\").strip()\n        if href and \"/dispensaries/\" in href and href not in seen and looks_like_florida(href, txt):\n            seen.add(href); out.append((\" \".join(txt.split()), urljoin(BASE, href)))\n    uniq, names = [], set()\n    for name, url in out:\n        if name not in names: names.add(name); uniq.append((name, url))\n    return uniq\n\nasync def load_all(page):\n    while True:\n        await page.mouse.wheel(0, 40000); await page.wait_for_timeout(random.randint(800, 1400))\n        btn = page.get_by_role(\"button\", name=re.compile(r\"Load More\", re.I))\n        if await btn.count() and await btn.first().is_visible():\n            try: await btn.first().click(); await page.wait_for_timeout(random.randint(1000,1600)); continue\n            except: pass\n        break\n\nasync def extract_price_from_card(card):\n    c = card.locator(\".price, [class*='price'], :text('$'):not(:text('Add to Wishlist'))\")\n    try:\n        n = min(await c.count(), 4); texts=[]\n        for i in range(n):\n            t = await c.nth(i).text_content()\n            if t and \"$\" in t: texts.append(t)\n        blob = \" \".join(texts) if texts else (await card.inner_text())\n    except: blob = (await card.inner_text())\n    vals = [float(m.group(1)) for m in PRICE_RE.finditer(blob or \"\")]\n    return min(vals) if vals else None\n\nasync def extract_price_from_pdp(ctx, url):\n    try:\n        p = await ctx.new_page()\n        await p.goto(url, wait_until=\"domcontentloaded\", timeout=20000)\n        body = await p.locator(\"body\").inner_text(); await p.close()\n        vals = [float(m.group(1)) for m in PRICE_RE.finditer(body or \"\")]\n        return min(vals) if vals else None\n    except (PWTimeout, Exception): return None\n\nasync def extract_brand_from_card(card):\n    try:\n        bel = card.locator(\".ProductCard_brand, .brand, .c-product-card__brand, [class*='Brand'], [data-testid*='brand']\")\n        if await bel.count():\n            txt = (await bel.first.text_content() or \"\").strip()\n            if txt: return txt\n    except: pass\n    return None\n\nasync def extract_brand_from_pdp(ctx, url):\n    try:\n        p = await ctx.new_page()\n        await p.goto(url, wait_until=\"domcontentloaded\", timeout=20000)\n        # breadcrumb / meta\n        crumbs = p.locator(\"nav a, .breadcrumb a, [class*='breadcrumb'] a\")\n        if await crumbs.count():\n            vals=[]\n            for i in range(min(5, await crumbs.count())):\n                t=(await crumbs.nth(i).text_content() or \"\").strip()\n                if t: vals.append(t)\n            for v in vals:\n                if v.lower() not in (\"home\",\"flower\",\"pre-rolls\",\"minis\",\"ground & shake\",\"products\",\"shop\"):\n                    if 1<=len(v)<=40: await p.close(); return v\n        # labeled line\n        label = p.locator(\"text=/Brand\\\\s*:/i\")\n        if await label.count():\n            line = await label.first.text_content()\n            if line and \":\" in line:\n                b=line.split(\":\",1)[1].strip()\n                if b: await p.close(); return b\n        meta = p.locator(\"[data-brand], [itemprop='brand'], [class*='brand']\")\n        if await meta.count():\n            t=(await meta.first.text_content() or \"\").strip()\n            if t: await p.close(); return t\n        body = await p.locator(\"body\").inner_text()\n        m = re.search(r\"Brand\\s*[:\\-]\\s*([^\\n\\r]+)\", body, flags=re.I)\n        await p.close()\n        return m.group(1).strip() if m else None\n    except (PWTimeout, Exception): return None\n\nasync def scrape_category(page, ctx, store_name):\n    await page.goto(CATEGORY_URL, wait_until=\"domcontentloaded\"); await load_all(page)\n    name_links = await page.locator(\"a[href*='/product/']:not(:has(img))\").all()\n    rows, seen = [], set()\n    for link in name_links:\n        try:\n            name = ((await link.text_content()) or \"\").strip()\n            if not name: continue\n            href = await link.get_attribute(\"href\"); url = urljoin(BASE, href) if href else None\n            slug = product_slug(href or \"\")\n            card = link.locator(\"xpath=ancestor::*[self::article or self::li or self::div][1]\")\n            card_text = (await card.inner_text()) if await card.count() else name\n\n            size = (SIZE_RE.search(card_text).group(1).lower() if SIZE_RE.search(card_text) else None)\n            grams = grams_from_size(size)\n\n            price = await extract_price_from_card(card)\n            brand = await extract_brand_from_card(card)\n            if (price is None or brand is None) and url:\n                if price is None: \n                    p = await extract_price_from_pdp(ctx, url)\n                    if p is not None: price = p\n                if brand is None:\n                    b = await extract_brand_from_pdp(ctx, url)\n                    if b: brand = b\n\n            strain_type=None\n            st_el = card.locator(\"text=/\\\\b(Indica|Sativa|Hybrid)\\\\b/i\")\n            if await st_el.count():\n                t=(await st_el.first.text_content()) or \"\"\n                m=re.search(r\"(Indica|Sativa|Hybrid)\", t, re.I)\n                if m: strain_type=m.group(1).capitalize()\n            if not strain_type:\n                for kw in (\"Indica\",\"Sativa\",\"Hybrid\"):\n                    if re.search(rf\"\\b{kw}\\b\", card_text, re.I): strain_type=kw; break\n\n            thc_pct=None\n            mr=THC_RANGE_RE.search(card_text)\n            if mr:\n                try: thc_pct=float(mr.group(1))\n                except: pass\n            if thc_pct is None:\n                ms=THC_SINGLE_RE.search(card_text)\n                if ms:\n                    try: thc_pct=float(ms.group(1))\n                    except: pass\n\n            key=(store_name, slug, size, SUBCATEGORY)\n            if key in seen: continue\n            seen.add(key)\n\n            rows.append({\n                \"state\":\"FL\",\"store\":store_name,\"subcategory\":SUBCATEGORY,\"name\":name,\"brand\":brand,\n                \"strain_type\":strain_type,\"thc_pct\":thc_pct,\"size_raw\":size,\"grams\":grams,\n                \"price\":price,\"price_per_g\":(round(price/grams,2) if price and grams else None),\"url\":url\n            })\n        except: continue\n    return rows\n\nasync def run(headless=True):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=headless, args=[\"--no-sandbox\"])\n        ctx = await browser.new_context(user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126 Safari/537.36\")\n        page = await ctx.new_page()\n\n        stores = await extract_fl_store_links(page)\n        all_rows=[]\n        for store_name, store_url in stores:\n            await page.wait_for_timeout(random.randint(700,1500))\n            try:\n                await page.goto(store_url, wait_until=\"domcontentloaded\")\n                btn = page.get_by_role(\"button\", name=re.compile(r\"Shop At This Store\", re.I))\n                if await btn.count():\n                    try: await btn.first().click(); await page.wait_for_timeout(random.randint(900,1400))\n                    except: pass\n            except: continue\n            rows = await scrape_category(page, ctx, store_name); all_rows.extend(rows)\n\n        await browser.close()\n\n    global DF_WHOLE_FLOWER\n    DF_WHOLE_FLOWER = pd.DataFrame(all_rows).sort_values([\"store\",\"brand\",\"name\",\"grams\"], kind=\"stable\")\n    DF_WHOLE_FLOWER.to_csv(Path(f\"{OUT_PREFIX}.csv\"), index=False)\n    DF_WHOLE_FLOWER.to_parquet(Path(f\"{OUT_PREFIX}.parquet\"), index=False)\n    print(f\"Wrote {len(DF_WHOLE_FLOWER):,} rows across {DF_WHOLE_FLOWER['store'].nunique() if len(DF_WHOLE_FLOWER) else 0} FL stores.\")\n\nif __name__ == \"__main__\":\n    import sys\n    if sys.platform == \"win32\":\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n    try:\n        asyncio.get_running_loop()\n        import nest_asyncio; nest_asyncio.apply()\n        asyncio.get_event_loop().run_until_complete(run(headless=True))\n    except RuntimeError:\n        asyncio.run(run(headless=True))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Wrote 2,544 rows across 159 FL stores.\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"import asyncio, re, random\nfrom pathlib import Path\nimport pandas as pd\nfrom urllib.parse import urljoin\nfrom playwright.async_api import async_playwright, TimeoutError as PWTimeout\n\nBASE = \"https://www.trulieve.com\"\nDISPENSARIES_URL = f\"{BASE}/dispensaries\"\nCATEGORY_URL = f\"{BASE}/category/flower/minis\"\nSUBCATEGORY  = \"Ground & Shake\"\nOUT_PREFIX   = \"trulieve_FL_ground_shake\"\n\nPRICE_RE        = re.compile(r\"\\$\\s*([0-9]+(?:\\.[0-9]{2})?)\")\nSIZE_RE         = re.compile(r\"\\b(0\\.5g|1g|2g|3\\.5g|7g|10g|14g|28g)\\b\", re.I)\nTHC_SINGLE_RE   = re.compile(r\"\\bTHC\\b[^0-9]*([0-9]+(?:\\.[0-9]+)?)\\s*%\", re.I)\nTHC_RANGE_RE    = re.compile(r\"\\bTHC\\b[^0-9]*([0-9]+(?:\\.[0-9]+)?)\\s*%[^0-9]+([0-9]+(?:\\.[0-9]+)?)\\s*%\", re.I)\nSIZE_MAP = {\"0.5g\":0.5,\"1g\":1.0,\"2g\":2.0,\"3.5g\":3.5,\"7g\":7.0,\"10g\":10.0,\"14g\":14.0,\"28g\":28.0}\ndef grams_from_size(s): return SIZE_MAP.get((s or \"\").lower())\n\ndef looks_like_florida(href, text):\n    t=(text or \"\").upper(); h=(href or \"\").lower()\n    return (\", FL\" in t) or t.endswith(\" FL\") or \" FL \" in t or any(v in h for v in (\"/florida\",\"-fl-\")) or h.endswith((\"/fl\",\"-fl\"))\n\ndef product_slug(href):\n    try: return href.split(\"/product/\",1)[1].split(\"?\",1)[0].split(\"#\",1)[0].strip(\"/\")\n    except: return href or \"\"\n\nasync def extract_fl_store_links(page):\n    await page.goto(DISPENSARIES_URL, wait_until=\"networkidle\")\n    anchors = await page.locator(\"a[href^='/dispensaries/']\").all()\n    out, seen = [], set()\n    for a in anchors:\n        href = await a.get_attribute(\"href\"); txt = (await a.text_content() or \"\").strip()\n        if href and \"/dispensaries/\" in href and href not in seen and looks_like_florida(href, txt):\n            seen.add(href); out.append((\" \".join(txt.split()), urljoin(BASE, href)))\n    uniq, names = [], set()\n    for name, url in out:\n        if name not in names: names.add(name); uniq.append((name, url))\n    return uniq\n\nasync def load_all(page):\n    while True:\n        await page.mouse.wheel(0, 40000); await page.wait_for_timeout(random.randint(800, 1400))\n        btn = page.get_by_role(\"button\", name=re.compile(r\"Load More\", re.I))\n        if await btn.count() and await btn.first().is_visible():\n            try: await btn.first().click(); await page.wait_for_timeout(random.randint(1000,1600)); continue\n            except: pass\n        break\n\nasync def extract_price_from_card(card):\n    c = card.locator(\".price, [class*='price'], :text('$'):not(:text('Add to Wishlist'))\")\n    try:\n        n = min(await c.count(), 4); texts=[]\n        for i in range(n):\n            t = await c.nth(i).text_content()\n            if t and \"$\" in t: texts.append(t)\n        blob = \" \".join(texts) if texts else (await card.inner_text())\n    except: blob = (await card.inner_text())\n    vals = [float(m.group(1)) for m in PRICE_RE.finditer(blob or \"\")]\n    return min(vals) if vals else None\n\nasync def extract_price_from_pdp(ctx, url):\n    try:\n        p = await ctx.new_page()\n        await p.goto(url, wait_until=\"domcontentloaded\", timeout=20000)\n        body = await p.locator(\"body\").inner_text(); await p.close()\n        vals = [float(m.group(1)) for m in PRICE_RE.finditer(body or \"\")]\n        return min(vals) if vals else None\n    except (PWTimeout, Exception): return None\n\nasync def extract_brand_from_card(card):\n    try:\n        bel = card.locator(\".ProductCard_brand, .brand, .c-product-card__brand, [class*='Brand'], [data-testid*='brand']\")\n        if await bel.count():\n            txt = (await bel.first.text_content() or \"\").strip()\n            if txt: return txt\n    except: pass\n    return None\n\nasync def extract_brand_from_pdp(ctx, url):\n    try:\n        p = await ctx.new_page()\n        await p.goto(url, wait_until=\"domcontentloaded\", timeout=20000)\n        # breadcrumb / meta\n        crumbs = p.locator(\"nav a, .breadcrumb a, [class*='breadcrumb'] a\")\n        if await crumbs.count():\n            vals=[]\n            for i in range(min(5, await crumbs.count())):\n                t=(await crumbs.nth(i).text_content() or \"\").strip()\n                if t: vals.append(t)\n            for v in vals:\n                if v.lower() not in (\"home\",\"flower\",\"pre-rolls\",\"minis\",\"ground & shake\",\"products\",\"shop\"):\n                    if 1<=len(v)<=40: await p.close(); return v\n        # labeled line\n        label = p.locator(\"text=/Brand\\\\s*:/i\")\n        if await label.count():\n            line = await label.first.text_content()\n            if line and \":\" in line:\n                b=line.split(\":\",1)[1].strip()\n                if b: await p.close(); return b\n        meta = p.locator(\"[data-brand], [itemprop='brand'], [class*='brand']\")\n        if await meta.count():\n            t=(await meta.first.text_content() or \"\").strip()\n            if t: await p.close(); return t\n        body = await p.locator(\"body\").inner_text()\n        m = re.search(r\"Brand\\s*[:\\-]\\s*([^\\n\\r]+)\", body, flags=re.I)\n        await p.close()\n        return m.group(1).strip() if m else None\n    except (PWTimeout, Exception): return None\n\nasync def scrape_category(page, ctx, store_name):\n    await page.goto(CATEGORY_URL, wait_until=\"domcontentloaded\"); await load_all(page)\n    name_links = await page.locator(\"a[href*='/product/']:not(:has(img))\").all()\n    rows, seen = [], set()\n    for link in name_links:\n        try:\n            name = ((await link.text_content()) or \"\").strip()\n            if not name: continue\n            href = await link.get_attribute(\"href\"); url = urljoin(BASE, href) if href else None\n            slug = product_slug(href or \"\")\n            card = link.locator(\"xpath=ancestor::*[self::article or self::li or self::div][1]\")\n            card_text = (await card.inner_text()) if await card.count() else name\n\n            size = (SIZE_RE.search(card_text).group(1).lower() if SIZE_RE.search(card_text) else None)\n            grams = grams_from_size(size)\n\n            price = await extract_price_from_card(card)\n            brand = await extract_brand_from_card(card)\n            if (price is None or brand is None) and url:\n                if price is None: \n                    p = await extract_price_from_pdp(ctx, url)\n                    if p is not None: price = p\n                if brand is None:\n                    b = await extract_brand_from_pdp(ctx, url)\n                    if b: brand = b\n\n            strain_type=None\n            st_el = card.locator(\"text=/\\\\b(Indica|Sativa|Hybrid)\\\\b/i\")\n            if await st_el.count():\n                t=(await st_el.first.text_content()) or \"\"\n                m=re.search(r\"(Indica|Sativa|Hybrid)\", t, re.I)\n                if m: strain_type=m.group(1).capitalize()\n            if not strain_type:\n                for kw in (\"Indica\",\"Sativa\",\"Hybrid\"):\n                    if re.search(rf\"\\b{kw}\\b\", card_text, re.I): strain_type=kw; break\n\n            thc_pct=None\n            mr=THC_RANGE_RE.search(card_text)\n            if mr:\n                try: thc_pct=float(mr.group(1))\n                except: pass\n            if thc_pct is None:\n                ms=THC_SINGLE_RE.search(card_text)\n                if ms:\n                    try: thc_pct=float(ms.group(1))\n                    except: pass\n\n            key=(store_name, slug, size, SUBCATEGORY)\n            if key in seen: continue\n            seen.add(key)\n\n            rows.append({\n                \"state\":\"FL\",\"store\":store_name,\"subcategory\":SUBCATEGORY,\"name\":name,\"brand\":brand,\n                \"strain_type\":strain_type,\"thc_pct\":thc_pct,\"size_raw\":size,\"grams\":grams,\n                \"price\":price,\"price_per_g\":(round(price/grams,2) if price and grams else None),\"url\":url\n            })\n        except: continue\n    return rows\n\nasync def run(headless=True):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=headless, args=[\"--no-sandbox\"])\n        ctx = await browser.new_context(user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126 Safari/537.36\")\n        page = await ctx.new_page()\n\n        stores = await extract_fl_store_links(page)\n        all_rows=[]\n        for store_name, store_url in stores:\n            await page.wait_for_timeout(random.randint(700,1500))\n            try:\n                await page.goto(store_url, wait_until=\"domcontentloaded\")\n                btn = page.get_by_role(\"button\", name=re.compile(r\"Shop At This Store\", re.I))\n                if await btn.count():\n                    try: await btn.first().click(); await page.wait_for_timeout(random.randint(900,1400))\n                    except: pass\n            except: continue\n            rows = await scrape_category(page, ctx, store_name); all_rows.extend(rows)\n\n        await browser.close()\n\n    global DF_GROUND_SHAKE\n    DF_GROUND_SHAKE = pd.DataFrame(all_rows).sort_values([\"store\",\"brand\",\"name\",\"grams\"], kind=\"stable\")\n    DF_GROUND_SHAKE.to_csv(Path(f\"{OUT_PREFIX}.csv\"), index=False)\n    DF_GROUND_SHAKE.to_parquet(Path(f\"{OUT_PREFIX}.parquet\"), index=False)\n    print(f\"Wrote {len(DF_GROUND_SHAKE):,} rows across {DF_GROUND_SHAKE['store'].nunique() if len(DF_GROUND_SHAKE) else 0} FL stores.\")\n\nif __name__ == \"__main__\":\n    import sys\n    if sys.platform == \"win32\":\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n    try:\n        asyncio.get_running_loop()\n        import nest_asyncio; nest_asyncio.apply()\n        asyncio.get_event_loop().run_until_complete(run(headless=True))\n    except RuntimeError:\n        asyncio.run(run(headless=True))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Wrote 2,544 rows across 159 FL stores.\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"import asyncio, re, random\nfrom pathlib import Path\nimport pandas as pd\nfrom urllib.parse import urljoin\nfrom playwright.async_api import async_playwright, TimeoutError as PWTimeout\n\nBASE = \"https://www.trulieve.com\"\nDISPENSARIES_URL = f\"{BASE}/dispensaries\"\nCATEGORY_URL = f\"{BASE}/category/flower/pre-rolls\"\nSUBCATEGORY  = \"Pre-Rolls\"\nOUT_PREFIX   = \"trulieve_FL_pre_rolls\"\n\nPRICE_RE        = re.compile(r\"\\$\\s*([0-9]+(?:\\.[0-9]{2})?)\")\nSIZE_RE         = re.compile(r\"\\b(0\\.5g|1g|2g|3\\.5g|7g|10g|14g|28g)\\b\", re.I)\nTHC_SINGLE_RE   = re.compile(r\"\\bTHC\\b[^0-9]*([0-9]+(?:\\.[0-9]+)?)\\s*%\", re.I)\nTHC_RANGE_RE    = re.compile(r\"\\bTHC\\b[^0-9]*([0-9]+(?:\\.[0-9]+)?)\\s*%[^0-9]+([0-9]+(?:\\.[0-9]+)?)\\s*%\", re.I)\nSIZE_MAP = {\"0.5g\":0.5,\"1g\":1.0,\"2g\":2.0,\"3.5g\":3.5,\"7g\":7.0,\"10g\":10.0,\"14g\":14.0,\"28g\":28.0}\ndef grams_from_size(s): return SIZE_MAP.get((s or \"\").lower())\n\ndef looks_like_florida(href, text):\n    t=(text or \"\").upper(); h=(href or \"\").lower()\n    return (\", FL\" in t) or t.endswith(\" FL\") or \" FL \" in t or any(v in h for v in (\"/florida\",\"-fl-\")) or h.endswith((\"/fl\",\"-fl\"))\n\ndef product_slug(href):\n    try: return href.split(\"/product/\",1)[1].split(\"?\",1)[0].split(\"#\",1)[0].strip(\"/\")\n    except: return href or \"\"\n\nasync def extract_fl_store_links(page):\n    await page.goto(DISPENSARIES_URL, wait_until=\"networkidle\")\n    anchors = await page.locator(\"a[href^='/dispensaries/']\").all()\n    out, seen = [], set()\n    for a in anchors:\n        href = await a.get_attribute(\"href\"); txt = (await a.text_content() or \"\").strip()\n        if href and \"/dispensaries/\" in href and href not in seen and looks_like_florida(href, txt):\n            seen.add(href); out.append((\" \".join(txt.split()), urljoin(BASE, href)))\n    uniq, names = [], set()\n    for name, url in out:\n        if name not in names: names.add(name); uniq.append((name, url))\n    return uniq\n\nasync def load_all(page):\n    while True:\n        await page.mouse.wheel(0, 40000); await page.wait_for_timeout(random.randint(800, 1400))\n        btn = page.get_by_role(\"button\", name=re.compile(r\"Load More\", re.I))\n        if await btn.count() and await btn.first().is_visible():\n            try: await btn.first().click(); await page.wait_for_timeout(random.randint(1000,1600)); continue\n            except: pass\n        break\n\nasync def extract_price_from_card(card):\n    c = card.locator(\".price, [class*='price'], :text('$'):not(:text('Add to Wishlist'))\")\n    try:\n        n = min(await c.count(), 4); texts=[]\n        for i in range(n):\n            t = await c.nth(i).text_content()\n            if t and \"$\" in t: texts.append(t)\n        blob = \" \".join(texts) if texts else (await card.inner_text())\n    except: blob = (await card.inner_text())\n    vals = [float(m.group(1)) for m in PRICE_RE.finditer(blob or \"\")]\n    return min(vals) if vals else None\n\nasync def extract_price_from_pdp(ctx, url):\n    try:\n        p = await ctx.new_page()\n        await p.goto(url, wait_until=\"domcontentloaded\", timeout=20000)\n        body = await p.locator(\"body\").inner_text(); await p.close()\n        vals = [float(m.group(1)) for m in PRICE_RE.finditer(body or \"\")]\n        return min(vals) if vals else None\n    except (PWTimeout, Exception): return None\n\nasync def extract_brand_from_card(card):\n    try:\n        bel = card.locator(\".ProductCard_brand, .brand, .c-product-card__brand, [class*='Brand'], [data-testid*='brand']\")\n        if await bel.count():\n            txt = (await bel.first.text_content() or \"\").strip()\n            if txt: return txt\n    except: pass\n    return None\n\nasync def extract_brand_from_pdp(ctx, url):\n    try:\n        p = await ctx.new_page()\n        await p.goto(url, wait_until=\"domcontentloaded\", timeout=20000)\n        # breadcrumb / meta\n        crumbs = p.locator(\"nav a, .breadcrumb a, [class*='breadcrumb'] a\")\n        if await crumbs.count():\n            vals=[]\n            for i in range(min(5, await crumbs.count())):\n                t=(await crumbs.nth(i).text_content() or \"\").strip()\n                if t: vals.append(t)\n            for v in vals:\n                if v.lower() not in (\"home\",\"flower\",\"pre-rolls\",\"minis\",\"ground & shake\",\"products\",\"shop\"):\n                    if 1<=len(v)<=40: await p.close(); return v\n        # labeled line\n        label = p.locator(\"text=/Brand\\\\s*:/i\")\n        if await label.count():\n            line = await label.first.text_content()\n            if line and \":\" in line:\n                b=line.split(\":\",1)[1].strip()\n                if b: await p.close(); return b\n        meta = p.locator(\"[data-brand], [itemprop='brand'], [class*='brand']\")\n        if await meta.count():\n            t=(await meta.first.text_content() or \"\").strip()\n            if t: await p.close(); return t\n        body = await p.locator(\"body\").inner_text()\n        m = re.search(r\"Brand\\s*[:\\-]\\s*([^\\n\\r]+)\", body, flags=re.I)\n        await p.close()\n        return m.group(1).strip() if m else None\n    except (PWTimeout, Exception): return None\n\nasync def scrape_category(page, ctx, store_name):\n    await page.goto(CATEGORY_URL, wait_until=\"domcontentloaded\"); await load_all(page)\n    name_links = await page.locator(\"a[href*='/product/']:not(:has(img))\").all()\n    rows, seen = [], set()\n    for link in name_links:\n        try:\n            name = ((await link.text_content()) or \"\").strip()\n            if not name: continue\n            href = await link.get_attribute(\"href\"); url = urljoin(BASE, href) if href else None\n            slug = product_slug(href or \"\")\n            card = link.locator(\"xpath=ancestor::*[self::article or self::li or self::div][1]\")\n            card_text = (await card.inner_text()) if await card.count() else name\n\n            size = (SIZE_RE.search(card_text).group(1).lower() if SIZE_RE.search(card_text) else None)\n            grams = grams_from_size(size)\n\n            price = await extract_price_from_card(card)\n            brand = await extract_brand_from_card(card)\n            if (price is None or brand is None) and url:\n                if price is None: \n                    p = await extract_price_from_pdp(ctx, url)\n                    if p is not None: price = p\n                if brand is None:\n                    b = await extract_brand_from_pdp(ctx, url)\n                    if b: brand = b\n\n            strain_type=None\n            st_el = card.locator(\"text=/\\\\b(Indica|Sativa|Hybrid)\\\\b/i\")\n            if await st_el.count():\n                t=(await st_el.first.text_content()) or \"\"\n                m=re.search(r\"(Indica|Sativa|Hybrid)\", t, re.I)\n                if m: strain_type=m.group(1).capitalize()\n            if not strain_type:\n                for kw in (\"Indica\",\"Sativa\",\"Hybrid\"):\n                    if re.search(rf\"\\b{kw}\\b\", card_text, re.I): strain_type=kw; break\n\n            thc_pct=None\n            mr=THC_RANGE_RE.search(card_text)\n            if mr:\n                try: thc_pct=float(mr.group(1))\n                except: pass\n            if thc_pct is None:\n                ms=THC_SINGLE_RE.search(card_text)\n                if ms:\n                    try: thc_pct=float(ms.group(1))\n                    except: pass\n\n            key=(store_name, slug, size, SUBCATEGORY)\n            if key in seen: continue\n            seen.add(key)\n\n            rows.append({\n                \"state\":\"FL\",\"store\":store_name,\"subcategory\":SUBCATEGORY,\"name\":name,\"brand\":brand,\n                \"strain_type\":strain_type,\"thc_pct\":thc_pct,\"size_raw\":size,\"grams\":grams,\n                \"price\":price,\"price_per_g\":(round(price/grams,2) if price and grams else None),\"url\":url\n            })\n        except: continue\n    return rows\n\nasync def run(headless=True):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=headless, args=[\"--no-sandbox\"])\n        ctx = await browser.new_context(user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126 Safari/537.36\")\n        page = await ctx.new_page()\n\n        stores = await extract_fl_store_links(page)\n        all_rows=[]\n        for store_name, store_url in stores:\n            await page.wait_for_timeout(random.randint(700,1500))\n            try:\n                await page.goto(store_url, wait_until=\"domcontentloaded\")\n                btn = page.get_by_role(\"button\", name=re.compile(r\"Shop At This Store\", re.I))\n                if await btn.count():\n                    try: await btn.first().click(); await page.wait_for_timeout(random.randint(900,1400))\n                    except: pass\n            except: continue\n            rows = await scrape_category(page, ctx, store_name); all_rows.extend(rows)\n\n        await browser.close()\n\n        global DF_PRE_ROLLS\n        DF_PRE_ROLLS = pd.DataFrame(all_rows).sort_values([\"store\",\"brand\",\"name\",\"grams\"], kind=\"stable\")\n        DF_PRE_ROLLS.to_csv(Path(f\"{OUT_PREFIX}.csv\"), index=False)\n        DF_PRE_ROLLS.to_parquet(Path(f\"{OUT_PREFIX}.parquet\"), index=False)\n        print(f\"Wrote {len(DF_PRE_ROLLS):,} rows across {DF_PRE_ROLLS['store'].nunique() if len(DF_PRE_ROLLS) else 0} FL stores.\")\n\nif __name__ == \"__main__\":\n    import sys\n    if sys.platform == \"win32\":\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n    try:\n        asyncio.get_running_loop()\n        import nest_asyncio; nest_asyncio.apply()\n        asyncio.get_event_loop().run_until_complete(run(headless=True))\n    except RuntimeError:\n        asyncio.run(run(headless=True))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Wrote 2,544 rows across 159 FL stores.\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"import asyncio, re, random\nfrom pathlib import Path\nimport pandas as pd\nfrom urllib.parse import urljoin\nfrom playwright.async_api import async_playwright, TimeoutError as PWTimeout\n\nBASE = \"https://www.trulieve.com\"\nDISPENSARIES_URL = f\"{BASE}/dispensaries\"\nCATEGORY_URL = f\"{BASE}/category/flower/ground-shake\"\nSUBCATEGORY  = \"Ground & Shake\"\nOUT_PREFIX   = \"trulieve_FL_ground_shake\"\n\nPRICE_RE        = re.compile(r\"\\$\\s*([0-9]+(?:\\.[0-9]{2})?)\")\nSIZE_RE         = re.compile(r\"\\b(0\\.5g|1g|2g|3\\.5g|7g|10g|14g|28g)\\b\", re.I)\nTHC_SINGLE_RE   = re.compile(r\"\\bTHC\\b[^0-9]*([0-9]+(?:\\.[0-9]+)?)\\s*%\", re.I)\nTHC_RANGE_RE    = re.compile(r\"\\bTHC\\b[^0-9]*([0-9]+(?:\\.[0-9]+)?)\\s*%[^0-9]+([0-9]+(?:\\.[0-9]+)?)\\s*%\", re.I)\nSIZE_MAP = {\"0.5g\":0.5,\"1g\":1.0,\"2g\":2.0,\"3.5g\":3.5,\"7g\":7.0,\"10g\":10.0,\"14g\":14.0,\"28g\":28.0}\ndef grams_from_size(s): return SIZE_MAP.get((s or \"\").lower())\n\ndef looks_like_florida(href, text):\n    t=(text or \"\").upper(); h=(href or \"\").lower()\n    return (\", FL\" in t) or t.endswith(\" FL\") or \" FL \" in t or any(v in h for v in (\"/florida\",\"-fl-\")) or h.endswith((\"/fl\",\"-fl\"))\n\ndef product_slug(href):\n    try: return href.split(\"/product/\",1)[1].split(\"?\",1)[0].split(\"#\",1)[0].strip(\"/\")\n    except: return href or \"\"\n\nasync def extract_fl_store_links(page):\n    await page.goto(DISPENSARIES_URL, wait_until=\"networkidle\")\n    anchors = await page.locator(\"a[href^='/dispensaries/']\").all()\n    out, seen = [], set()\n    for a in anchors:\n        href = await a.get_attribute(\"href\"); txt = (await a.text_content() or \"\").strip()\n        if href and \"/dispensaries/\" in href and href not in seen and looks_like_florida(href, txt):\n            seen.add(href); out.append((\" \".join(txt.split()), urljoin(BASE, href)))\n    uniq, names = [], set()\n    for name, url in out:\n        if name not in names: names.add(name); uniq.append((name, url))\n    return uniq\n\nasync def load_all(page):\n    while True:\n        await page.mouse.wheel(0, 40000); await page.wait_for_timeout(random.randint(800, 1400))\n        btn = page.get_by_role(\"button\", name=re.compile(r\"Load More\", re.I))\n        if await btn.count() and await btn.first().is_visible():\n            try: await btn.first().click(); await page.wait_for_timeout(random.randint(1000,1600)); continue\n            except: pass\n        break\n\nasync def extract_price_from_card(card):\n    c = card.locator(\".price, [class*='price'], :text('$'):not(:text('Add to Wishlist'))\")\n    try:\n        n = min(await c.count(), 4); texts=[]\n        for i in range(n):\n            t = await c.nth(i).text_content()\n            if t and \"$\" in t: texts.append(t)\n        blob = \" \".join(texts) if texts else (await card.inner_text())\n    except: blob = (await card.inner_text())\n    vals = [float(m.group(1)) for m in PRICE_RE.finditer(blob or \"\")]\n    return min(vals) if vals else None\n\nasync def extract_price_from_pdp(ctx, url):\n    try:\n        p = await ctx.new_page()\n        await p.goto(url, wait_until=\"domcontentloaded\", timeout=20000)\n        body = await p.locator(\"body\").inner_text(); await p.close()\n        vals = [float(m.group(1)) for m in PRICE_RE.finditer(body or \"\")]\n        return min(vals) if vals else None\n    except (PWTimeout, Exception): return None\n\nasync def extract_brand_from_card(card):\n    try:\n        bel = card.locator(\".ProductCard_brand, .brand, .c-product-card__brand, [class*='Brand'], [data-testid*='brand']\")\n        if await bel.count():\n            txt = (await bel.first.text_content() or \"\").strip()\n            if txt: return txt\n    except: pass\n    return None\n\nasync def extract_brand_from_pdp(ctx, url):\n    try:\n        p = await ctx.new_page()\n        await p.goto(url, wait_until=\"domcontentloaded\", timeout=20000)\n        # breadcrumb / meta\n        crumbs = p.locator(\"nav a, .breadcrumb a, [class*='breadcrumb'] a\")\n        if await crumbs.count():\n            vals=[]\n            for i in range(min(5, await crumbs.count())):\n                t=(await crumbs.nth(i).text_content() or \"\").strip()\n                if t: vals.append(t)\n            for v in vals:\n                if v.lower() not in (\"home\",\"flower\",\"pre-rolls\",\"minis\",\"ground & shake\",\"products\",\"shop\"):\n                    if 1<=len(v)<=40: await p.close(); return v\n        # labeled line\n        label = p.locator(\"text=/Brand\\\\s*:/i\")\n        if await label.count():\n            line = await label.first.text_content()\n            if line and \":\" in line:\n                b=line.split(\":\",1)[1].strip()\n                if b: await p.close(); return b\n        meta = p.locator(\"[data-brand], [itemprop='brand'], [class*='brand']\")\n        if await meta.count():\n            t=(await meta.first.text_content() or \"\").strip()\n            if t: await p.close(); return t\n        body = await p.locator(\"body\").inner_text()\n        m = re.search(r\"Brand\\s*[:\\-]\\s*([^\\n\\r]+)\", body, flags=re.I)\n        await p.close()\n        return m.group(1).strip() if m else None\n    except (PWTimeout, Exception): return None\n\nasync def scrape_category(page, ctx, store_name):\n    await page.goto(CATEGORY_URL, wait_until=\"domcontentloaded\"); await load_all(page)\n    name_links = await page.locator(\"a[href*='/product/']:not(:has(img))\").all()\n    rows, seen = [], set()\n    for link in name_links:\n        try:\n            name = ((await link.text_content()) or \"\").strip()\n            if not name: continue\n            href = await link.get_attribute(\"href\"); url = urljoin(BASE, href) if href else None\n            slug = product_slug(href or \"\")\n            card = link.locator(\"xpath=ancestor::*[self::article or self::li or self::div][1]\")\n            card_text = (await card.inner_text()) if await card.count() else name\n\n            size = (SIZE_RE.search(card_text).group(1).lower() if SIZE_RE.search(card_text) else None)\n            grams = grams_from_size(size)\n\n            price = await extract_price_from_card(card)\n            brand = await extract_brand_from_card(card)\n            if (price is None or brand is None) and url:\n                if price is None: \n                    p = await extract_price_from_pdp(ctx, url)\n                    if p is not None: price = p\n                if brand is None:\n                    b = await extract_brand_from_pdp(ctx, url)\n                    if b: brand = b\n\n            strain_type=None\n            st_el = card.locator(\"text=/\\\\b(Indica|Sativa|Hybrid)\\\\b/i\")\n            if await st_el.count():\n                t=(await st_el.first.text_content()) or \"\"\n                m=re.search(r\"(Indica|Sativa|Hybrid)\", t, re.I)\n                if m: strain_type=m.group(1).capitalize()\n            if not strain_type:\n                for kw in (\"Indica\",\"Sativa\",\"Hybrid\"):\n                    if re.search(rf\"\\b{kw}\\b\", card_text, re.I): strain_type=kw; break\n\n            thc_pct=None\n            mr=THC_RANGE_RE.search(card_text)\n            if mr:\n                try: thc_pct=float(mr.group(1))\n                except: pass\n            if thc_pct is None:\n                ms=THC_SINGLE_RE.search(card_text)\n                if ms:\n                    try: thc_pct=float(ms.group(1))\n                    except: pass\n\n            key=(store_name, slug, size, SUBCATEGORY)\n            if key in seen: continue\n            seen.add(key)\n\n            rows.append({\n                \"state\":\"FL\",\"store\":store_name,\"subcategory\":SUBCATEGORY,\"name\":name,\"brand\":brand,\n                \"strain_type\":strain_type,\"thc_pct\":thc_pct,\"size_raw\":size,\"grams\":grams,\n                \"price\":price,\"price_per_g\":(round(price/grams,2) if price and grams else None),\"url\":url\n            })\n        except: continue\n    return rows\n\nasync def run(headless=True):\n    async with async_playwright() as p:\n        browser = await p.chromium.launch(headless=headless, args=[\"--no-sandbox\"])\n        ctx = await browser.new_context(user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126 Safari/537.36\")\n        page = await ctx.new_page()\n\n        stores = await extract_fl_store_links(page)\n        all_rows=[]\n        for store_name, store_url in stores:\n            await page.wait_for_timeout(random.randint(700,1500))\n            try:\n                await page.goto(store_url, wait_until=\"domcontentloaded\")\n                btn = page.get_by_role(\"button\", name=re.compile(r\"Shop At This Store\", re.I))\n                if await btn.count():\n                    try: await btn.first().click(); await page.wait_for_timeout(random.randint(900,1400))\n                    except: pass\n            except: continue\n            rows = await scrape_category(page, ctx, store_name); all_rows.extend(rows)\n\n        await browser.close()\n        global DF_PRE_ROLLS\n        DF_PRE_ROLLS = pd.DataFrame(all_rows).sort_values([\"store\",\"brand\",\"name\",\"grams\"], kind=\"stable\")\n        DF_PRE_ROLLS.to_csv(Path(f\"{OUT_PREFIX}.csv\"), index=False)\n        DF_PRE_ROLLS.to_parquet(Path(f\"{OUT_PREFIX}.parquet\"), index=False)\n        print(f\"Wrote {len(DF_PRE_ROLLS):,} rows across {DF_PRE_ROLLS['store'].nunique() if len(DF_PRE_ROLLS) else 0} FL stores.\")\n        \n\nif __name__ == \"__main__\":\n    import sys\n    if sys.platform == \"win32\":\n        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n    try:\n        asyncio.get_running_loop()\n        import nest_asyncio; nest_asyncio.apply()\n        asyncio.get_event_loop().run_until_complete(run(headless=True))\n    except RuntimeError:\n        asyncio.run(run(headless=True))\n","metadata":{},"execution_count":null,"outputs":[{"data":{"text/plain":"Wrote 2,544 rows across 159 FL stores.\n"},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","source":"# if hex_run_context in [\"logic\"]:\n#     import hextoolkit\n#     hex_data_connection = hextoolkit.get_data_connection(\"Curaleaf Production Snowflake (New)\")\n#     writeback_metadata = hex_data_connection.write_dataframe(df=DF_WHOLE_FLOWER, database=\"SANDBOX_EDW\", schema=\"ANALYTICS\", table=\"TL_Scrape_WHOLE_FLOWER\", overwrite=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if hex_run_context in [\"logic\"]:\n#     import hextoolkit\n#     hex_data_connection = hextoolkit.get_data_connection(\"Curaleaf Production Snowflake (New)\")\n#     writeback_metadata = hex_data_connection.write_dataframe(df=DF_PRE_ROLLS, database=\"SANDBOX_EDW\", schema=\"ANALYTICS\", table=\"TL_Scrape_Pre_Rolls\", overwrite=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if hex_run_context in [\"logic\"]:\n#     import hextoolkit\n#     hex_data_connection = hextoolkit.get_data_connection(\"Curaleaf Production Snowflake (New)\")\n#     writeback_metadata = hex_data_connection.write_dataframe(df=DF_GROUND_SHAKE, database=\"SANDBOX_EDW\", schema=\"ANALYTICS\", table=\"TL_Scrape_Ground_Shake\", overwrite=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To do:\n\n- add time stamp to generated DF\n- publish and automate\n- Solve Brand miss\n- replicate for Muv\n\n","metadata":{}}],"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"hex_info":{"author":null,"project_id":"0198e707-161f-7003-bc17-9a8d006d2b71","version":"draft","exported_date":"Thu Aug 28 2025 21:11:03 GMT+0000 (Coordinated Universal Time)"}},"nbformat":4,"nbformat_minor":4}